\section{Joint NER and NEL in Newspaper Articles}
\label{sec:nel}

Newspaper articles contain a lot of current information about business relations. E.g., a German article might contain a sentence like: "`Bosch liefert Servomotoren an die DB."' (English: "`Bosch delivers servo motors to the DB."') For a human it is obvious that this sentence represents a delivery relation between the entities: "`Robert Bosch GmbH"' and "`Deutsche Bahn AG"'. While "`DB"' could also abbreviate "`Deutsche Bank"' [todo: AG?], the technical context makes clear that the railroad company (?) is meant instead of the bank.

As such relations are useful for our business graph, we want to extract those from free text, such as newspaper articles. In order to do so, we need to perform joint NER and NEL beforehand. This section describes how we identify which businesses are mentioned in free texts.\\

\subsection{Newspaper data sources}
Currently, we perform joint NER and NEL on the German Wikipedia and the German newspaper Spiegel Online [todo: link]. As Wikipedia already contains links to named entities, we use it as training data (see Sec.~\ref{sec:pipeline}) and ground truth for the evaluation [todo: reference jan]. Newspaper articles are missing such annotations.

For Spiegel Online, we use a dump that consists of HTML, contains 260000 articles (?) and has a total size of (?) GB. On (?) average, the text of each article consists of (?) characters.\\

\subsection{Process}
The joint NER and NEL consists of multiple steps, as depicted in Fig.~\ref{fig:ner_nel_process}. Apart from the data import, the steps are independent from the data source so that they can be reused easily.

[todo: Grafik mit Schritten]

\subsubsection{Data import}
For each article, the Spiegel Online dump provides the title, the text and a unique internal ID. We extract these three values from the dump and store them in a Cassandra table. As the German Wikipedia dump provides similar information, we store it in a table with the exact same format. The only difference to Spiegel Online is that the title of an article already is a unique ID.\\

\subsubsection{Potential named entity recognition}
A mention of a named entity in a text is a chain of one or more consecutive tokens, where a token is a semantic element of a text. This is a word in most cases, but can also be a special character, such as a comma. The task of named entity recognition is to identify such chains in text. This step is important for our process, as NEL needs to be performed on a pre-selection of those. Otherwise it would have to try to link each n-gram in the text to a named entity, which would lead to a computational complexity that increases exponential with the number of tokens. This would be inacceptable for our task.

[todo: Example with comma]

But in contrast to NER, we create a larger pre-selection of potential named entities that may signify a named entity depending on the context. This step is therefore called "`potential named entity recognition"'. It is much easier than NER, as NEL will decide to which named entity a named entity candidate links, which is a very similar task to deciding whether it links to a named entity at all. In our case, this is what NEL will do later on.

We find candidates of named entities simply by selecting all those token chains that were named entities of organizations in the training data (see Sec.~\ref{sec:alias_analysis}). An efficient way to match those is by means of a trie, which we implemented as a token based prefix tree.

[todo: explain logarithmic time]

\subsubsection{Feature extraction}
\subsubsection{NEL}
\subsubsection{HTML Export}
[todo: reference curation interface]

Random forest classifier\\
